{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federatedlearning2layernet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagirathtallapragada/Secure-AI-project-phase2/blob/main/Federatedlearning2layernet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjYCLnY600Y2"
      },
      "source": [
        "This notebook is an implementation to conduct federated learning using the CIFAR100 dataset with the following settings:\n",
        "Cases you need to consider:\n",
        "1) Every party has instances of every class, 2) Every party only holds instances of one class.\n",
        "\n",
        "Reporting training and test performance in the above settings with 10, 20, 50, 100 parties. Also report how fast the training converges and time it take to train with different number of parties involved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLqwL9nAp9pN",
        "outputId": "79f74cb2-d368-4ae7-91ff-11b94274e9cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kjrh2K6tJUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504b71b2-81b0-4293-da8d-9e660996236a"
      },
      "source": [
        "!pip install tensorflow_federated==0.13.1 --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 35.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 41.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 42.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 71 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 81 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 133 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 143 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 153 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 163 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 194 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 204 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 225 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 235 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 245 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 256 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 266 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 276 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 286 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 296 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 307 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 317 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 327 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 337 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 348 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 358 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 368 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 378 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 389 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 399 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 409 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 419 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 428 kB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 104 kB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 76.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 473 kB/s \n",
            "\u001b[K     |████████████████████████████████| 422.0 MB 33 kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 448 kB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 956 kB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.9 MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pymc3 3.11.4 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.17.5 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.17.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugj6pwbYmVjm"
      },
      "source": [
        "# !pip install --upgrade tensorflow --quiet\n",
        "# !pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URz6pyoYqYzL"
      },
      "source": [
        "# !pip uninstall --yes tensorboard tb-nightly\n",
        "# !pip install --quiet --upgrade tensorflow-federated-nightly\n",
        "# !pip install --quiet --upgrade nest-asyncio\n",
        "# !pip install --quiet --upgrade tb-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksja49SUCxP"
      },
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-QME01r_Aa"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDdNChWdsS1o"
      },
      "source": [
        "import collections\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import InputLayer, Reshape\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "np.random.seed(0)\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset   \n",
        "torch.backends.cudnn.benchmark=True\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W_zVo50usM7"
      },
      "source": [
        "# Next version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oadc_DyBuyHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fa1354-44ea-4142-be97-32a52989d112"
      },
      "source": [
        "(x_train_100, y_train_100), (x_test_100, y_test_100) = cifar100.load_data()\n",
        "x_train_100 = x_train_100.astype('float32')\n",
        "x_test_100 = x_test_100.astype('float32')\n",
        "x_train_100  /= 255\n",
        "x_test_100 /= 255"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5N-btywxP1p"
      },
      "source": [
        "def ext_classes( data, labels,n, cat_y = True):\n",
        "    data_cl=[]\n",
        "    y=[]\n",
        "    # print(data.shape)\n",
        "    for i in range(n):\n",
        "            # print(data[ np.argwhere( labels == i ).reshape(-1) ].shape)\n",
        "            # print(labels.shape)\n",
        "            # print(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1)].shape,data.shape)\n",
        "            data_cl.append(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1) ][ : ])\n",
        "            y.extend(np.full((data_cl[i].shape[0]), i, dtype=int))\n",
        "\n",
        "    # print(np.array(data_cl).shape)\n",
        "    x = np.vstack( (data_cl) )\n",
        "    y = np.array(y)\n",
        "    # print(\"In extract classes function\")\n",
        "    # print(x.shape,y.shape)\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khpDewX-wlgw"
      },
      "source": [
        "#extract equal ratio of all classes for training data\n",
        "x_train, y_train = ext_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHFHvX28iSnN"
      },
      "source": [
        "# for the test case\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGC4Inu_DzrL"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtpRazzLin91"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKYFpb6iiuFQ",
        "outputId": "609858d0-8264-40c6-d305-ae11f2992962"
      },
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              " array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pL-G5SDcHzB"
      },
      "source": [
        "## 1) Every party only holds instances of one class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgbTAVRWQY4E"
      },
      "source": [
        "#### 1) 10 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bA-mt5XlPR",
        "outputId": "89c0c972-71be-4157-913c-f37d420f5790"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uTgzDNIdwA8",
        "outputId": "4220c5cb-182d-494e-a6e8-d14dbec65c14"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixgnpkvg3-jP",
        "outputId": "b22c8592-140a-449c-c84b-0c4b82233afe"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eVxRHn2tzcb"
      },
      "source": [
        "def build_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "    for  i in range(98):\n",
        "        model.add( tf.keras.layers.Dense( 64, activation='relu' ) )\n",
        "    model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "    return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhZXUwuf31r_",
        "outputId": "5df44304-cf8c-4297-8d8b-d47244307ee1"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0 <sparse_categorical_accuracy=0.9959999918937683,loss=0.03382914885878563,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9964600205421448,loss=0.02134837582707405,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9963799715042114,loss=0.015984635800123215,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.9965199828147888,loss=0.013162602670490742,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.9966599941253662,loss=0.012213370762765408,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9965000152587891,loss=0.011557807214558125,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9965999722480774,loss=0.011338170617818832,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9965599775314331,loss=0.01136317290365696,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9965999722480774,loss=0.011057495139539242,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.996720016002655,loss=0.011854215525090694,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 72.23795127868652s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-qzc_Shf-Q"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oMyPLnQhb6y",
        "outputId": "b0eb2058-937f-459e-9794-7f75e8dba82a"
      },
      "source": [
        "NUM_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV425QoSkIGe",
        "outputId": "a0694a77-e6b2-4622-a331-fcd0b609eb39"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbQd37HkO97"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM4qhT3OmtS5",
        "outputId": "93d69a26-0710-4466-ca79-4b16e1670121"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.13699999451637268,loss=2.543506145477295,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hVQLH5uhcu5"
      },
      "source": [
        "### 2) 20 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir0Bvsv2pPXc"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = ext_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSn8xtVdpPXd"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xqlzpXApPXd"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9bU0WCpPXd"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiFihS584QVP",
        "outputId": "46dcdf41-6611-48b7-83c7-2fd2e8de9aeb"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwzFFsCMhcu6"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIm-gu6m8Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108dc9e5-767a-405a-fff7-8ff6c0f0ba95"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9960399866104126,loss=0.03697780519723892,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9962000250816345,loss=0.026739446446299553,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9962400197982788,loss=0.02325989305973053,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.996209979057312,loss=0.02068919688463211,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.9962499737739563,loss=0.018624814227223396,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9962400197982788,loss=0.017137035727500916,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9962800145149231,loss=0.015796171501278877,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9962999820709229,loss=0.01506357453763485,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9964100122451782,loss=0.014382858760654926,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9963799715042114,loss=0.013735824264585972,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 194.5364692211151s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTJ0I2kLm-Eq"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb1K9Iq-m-Eq",
        "outputId": "47d0b03c-88ea-4e84-8b23-609c1047a8b2"
      },
      "source": [
        "NUM_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab6294Jxm-Eq",
        "outputId": "87712924-a79a-42db-a70f-3d279f4c48f7"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVpe2-y8m-Er"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvyPrbgOm-Er",
        "outputId": "f5499fef-8eb0-41a2-9909-8a1b6d17503c"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.0989999994635582,loss=3.0804636478424072,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMUHww-1q5Hg"
      },
      "source": [
        "### 3) 50 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQyiIpbxrGLC"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = ext_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqGO5mMrGLC"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1eH6QIArGLC"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)\n",
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0dDoiQg4pPx",
        "outputId": "998f9e71-2f26-4193-ca53-e8dcbb2843cc"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTlj0B6OrGLD"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBlktaMmrGLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceab106-f947-4986-8821-461cad17238f"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9959440231323242,loss=0.037718288600444794,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9960839748382568,loss=0.031111428514122963,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9960759878158569,loss=0.028964880853891373,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.9960799813270569,loss=0.02710742875933647,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.9960960149765015,loss=0.025624044239521027,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9961040019989014,loss=0.02401348017156124,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9961000084877014,loss=0.022827167063951492,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9960960149765015,loss=0.021889837458729744,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9961159825325012,loss=0.02118147909641266,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9960920214653015,loss=0.020357223227620125,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 487.11325764656067s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf1tTWbprGLD"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWS_KRZKrGLD",
        "outputId": "a679997c-a4c1-4e51-9af6-9f4b43586bd2"
      },
      "source": [
        "NUM_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cri8T1BurGLD",
        "outputId": "6122789d-83b6-482d-ac59-7b2184bdb981"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS-EoQcUrGLD"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYgrBdH6rGLE",
        "outputId": "c5a1d3a9-37f5-40a0-e9ba-81ce922cbd7f"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.026200000196695328,loss=4.331847190856934,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJ-y3YXu7pH"
      },
      "source": [
        "### 3) 100 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA7fcwkBu7pH"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = ext_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtpZfkyTu7pH"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9_tnVQKu7pH"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)\n",
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FckEqLTs4_-4",
        "outputId": "157fda2e-ac07-43e7-f7a7-380d2c45dd66"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kk5HIjKu7pI"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loowpzQH5FTp",
        "outputId": "5f814eae-77b1-4db7-914b-42b07a7b0a25"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9960399866104126,loss=0.03543030098080635,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9960319995880127,loss=0.03061618283390999,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9960259795188904,loss=0.028964536264538765,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.9960280060768127,loss=0.027742359787225723,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.9960299730300903,loss=0.02672729082405567,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9960280060768127,loss=0.025807589292526245,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9960359930992126,loss=0.02511356584727764,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9960399866104126,loss=0.024394679814577103,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9960640072822571,loss=0.023861154913902283,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9960439801216125,loss=0.02329021506011486,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 1004.8828163146973s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HVaPn0_u7pI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDTsGl-0u7pI",
        "outputId": "fad07567-cc1f-4954-a4a4-46b3efff0c8e"
      },
      "source": [
        "NUM_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhz1r96Su7pI",
        "outputId": "06b2f72a-f2c8-40c6-d0cf-c8d66fba09ed"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrYtGQLeu7pI"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdcNE9ciu7pJ",
        "outputId": "703aa521-03a4-4ab0-d4cb-04fe54b3b7cd"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.010200000368058681,loss=4.990439414978027,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrXvu7Cx5j_7"
      },
      "source": [
        "state, metrics = algorithm.next( state, data )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FBUXiI5m7W",
        "outputId": "2b24f5ae-1f4d-4a5f-8d8b-9e4636bdd26a"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnonymousTuple([('sparse_categorical_accuracy', 0.99), ('loss', 0.054717205), ('keras_training_time_client_sum_sec', 0.0)])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XnZs4v50CC"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r2HAGXd52_e",
        "outputId": "0a24febc-9138-46dc-a077-9bf91ffe5fc4"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.011900000274181366,loss=4.932197093963623,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veWUt8aO6u9C"
      },
      "source": [
        "## 1) Every party has instances of every class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u7piAo9NcWH"
      },
      "source": [
        "def ext_classes( data, labels,n, cat_y = True):\n",
        "    data_cl=[]\n",
        "    y=[]\n",
        "    # print(data.shape)\n",
        "    for i in range(n):\n",
        "            # print(data[ np.argwhere( labels == i ).reshape(-1) ].shape)\n",
        "            # print(labels.shape)\n",
        "            # print(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1)].shape,data.shape)\n",
        "            data_cl.append(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1) ][ : ])\n",
        "            y.extend(np.full((data_cl[i].shape[0]), i, dtype=int))\n",
        "\n",
        "    # print(np.array(data_cl).shape)\n",
        "    x = np.vstack( (data_cl) )\n",
        "    y = np.array(y)\n",
        "    # print(\"In extract classes function\")\n",
        "    # print(x.shape,y.shape)\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI36lI8SO_bt"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = ext_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session = tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EwhF66BgL_f"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)\n",
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS3LZBBPP7cu"
      },
      "source": [
        "x_new = []\n",
        "y_new = []\n",
        "for i in range(500):\n",
        "    for j in range(x_train.shape[0]//500):\n",
        "        x_new.append(x_train[j*500+i])\n",
        "        y_new.append(y_train[j*500+i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ndqWGJbaVqm",
        "outputId": "5d35410e-39f2-4f89-bc15-1679ce53e1c2"
      },
      "source": [
        "x_new = np.array(x_new)\n",
        "x_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm8R_k_ofHsG",
        "outputId": "ed29d92e-5ccf-41e1-bd56-fcd8af961a3f"
      },
      "source": [
        "y_new = np.array(y_new)\n",
        "y_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaM8Uuo6u9D"
      },
      "source": [
        "### 1) 10 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEuN1ZnZf5Vy"
      },
      "source": [
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj2C4ogl5chq",
        "outputId": "128663ee-be87-46d0-d541-46e212c2dbfe"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NUM_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeTXLXa86u9F"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwrAD80z5hEK",
        "outputId": "f90f7d04-9796-49f7-a866-abfedaabb30d"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.05278199911117554,loss=4.266721725463867,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.11944799870252609,loss=3.8055810928344727,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.1584240049123764,loss=3.5800442695617676,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.18024800717830658,loss=3.458298683166504,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.1968819946050644,loss=3.3686110973358154,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.2101839929819107,loss=3.2939107418060303,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.22045199573040009,loss=3.233283519744873,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.23027199506759644,loss=3.178624391555786,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.24020999670028687,loss=3.1305060386657715,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.24805399775505066,loss=3.088498592376709,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 741.3998596668243s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCDcKszC6u9G"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bRj9l0z6u9H",
        "outputId": "3fdb744a-bbab-4646-eadb-fe9e3cee05ed"
      },
      "source": [
        "NUM_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(NUM_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoBH3W1w6u9I",
        "outputId": "14c82410-3d10-45af-b430-099a5a5222ed"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwMOPsi6u9I"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shOZzAp_6u9J",
        "outputId": "12ed36f0-2704-48e5-d258-0b6262959788"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.2160000056028366,loss=3.3676819801330566,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr8D6oJT6u9J"
      },
      "source": [
        "### 2) 20 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_BNSjTP6u9K"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avUiBIA86u9K"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIGYu8QD5q8o",
        "outputId": "0bb1f01d-5e5d-4ae7-fe6e-78a5acd41790"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1e6dWKc6u9N"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XEvmepD6u9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ec743e-2afa-48b7-ea28-b996b54bf093"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.03710800036787987,loss=4.415712356567383,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.09107399731874466,loss=3.982799768447876,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.13134799897670746,loss=3.7303619384765625,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.1572359949350357,loss=3.595865488052368,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.17455799877643585,loss=3.5044467449188232,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.18874800205230713,loss=3.4305524826049805,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.19981999695301056,loss=3.366664171218872,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.2102780044078827,loss=3.3098437786102295,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.21979600191116333,loss=3.259394645690918,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.22829799354076385,loss=3.2135140895843506,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 792.0462806224823s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3C8S-3t6u9O"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5b2PAqH6u9P",
        "outputId": "edffc51a-b256-4866-f9ea-3ea342a60189"
      },
      "source": [
        "NUM_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(NUM_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvaxHS-_6u9Q",
        "outputId": "1ffdffcd-502e-45d9-c7f3-91b15769cf89"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_esaP0H6u9Q"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-EWbOZ36u9Q",
        "outputId": "936195f9-8b43-4087-9d03-2a21ea306e32"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.19679999351501465,loss=3.478153944015503,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KdhJ9V6u9R"
      },
      "source": [
        "### 3) 50 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4WSFdpN6u9S"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RASacLdd6u9S"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cff06wF85_aN",
        "outputId": "b92c566d-d80c-4642-cf00-04a1566decb5"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQi1q2ST6u9W"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1yV0-ic6u9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187e5241-3e36-4bc1-eabc-47b311c33aa9"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.0303179994225502,loss=4.498284339904785,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.06439799815416336,loss=4.212356090545654,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.09606199711561203,loss=3.950756549835205,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.11937999725341797,loss=3.8029637336730957,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.13729199767112732,loss=3.692713499069214,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.15332800149917603,loss=3.6051816940307617,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.16589200496673584,loss=3.536808967590332,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.17592200636863708,loss=3.478910207748413,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.1857299953699112,loss=3.429701805114746,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.19409799575805664,loss=3.387822151184082,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 909.5469431877136s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilRqeeKO6u9X"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL9o46fE6u9Y",
        "outputId": "a787f0e1-1f89-47c7-dc34-f531744bc88f"
      },
      "source": [
        "NUM_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(NUM_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uPIh5lZ6u9Y",
        "outputId": "6d4828ea-4848-42f7-cccf-ed9822a6ae3d"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zErBKnzz6u9Z"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlpeuOTT6u9Z",
        "outputId": "6a24d0be-ac82-48f4-d957-04a028869870"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.16290000081062317,loss=3.6425647735595703,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUAo6rqz6u9a"
      },
      "source": [
        "### 4) 100 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK4xsLHN6u9b"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtOILS9R6u9b"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = ext_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqCcBTQ66eJH",
        "outputId": "305ee592-00cc-4e44-93bf-84f3656cdd85"
      },
      "source": [
        "# parameters\n",
        "NUM_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irc8j2l6u9d"
      },
      "source": [
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZMFl1lv6jkS",
        "outputId": "1ec53944-d26c-4458-d2e6-b330ea452632"
      },
      "source": [
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f74535cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.024922000244259834,loss=4.54674768447876,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.04081999883055687,loss=4.447535514831543,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.061785999685525894,loss=4.275726795196533,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.0836699977517128,loss=4.071457862854004,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.10298199951648712,loss=3.918820381164551,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.11763600260019302,loss=3.8149516582489014,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.13095399737358093,loss=3.7343668937683105,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.1424880027770996,loss=3.667412757873535,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.1517219990491867,loss=3.6102752685546875,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.16169199347496033,loss=3.5592072010040283,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 1064.7086291313171s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05kAABtz6u9e"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNTaNxUr6u9e",
        "outputId": "3382e206-43c0-4374-f8ec-cd1395edf444"
      },
      "source": [
        "NUM_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NUM_CLIENT_SAMPLES = TOTAL_SAMPLES // NUM_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NUM_CLIENTS ):\n",
        "  x = x_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES  ].reshape(NUM_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NUM_CLIENT_SAMPLES : ( i + 1 ) * NUM_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn3P3wQP6u9e",
        "outputId": "7c464ae3-237b-4d14-c947-76299773edae"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cVIiXd6u9f"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5hwji_F6u9f",
        "outputId": "a3b5e320-6ad7-4955-ceb7-9db6b9152e08"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.1396999955177307,loss=3.7924530506134033,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    }
  ]
}